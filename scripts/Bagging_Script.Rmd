---
title: "Bagging Pipeline: CBCL"
author: "Jacob DeRosa"
output:
  html_document:
    number_sections: no
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
      
---

```{r, echo = F, include = F}


#load Libraries 
library(knitr)
library(dplyr)
library(purrr)
library(reshape2)
library(tidyr)
library(stringi)
library(ggplot2)
library(ggiraphExtra)
library(gplots)
library(RColorBrewer)
library(viridis)
library(viridis)
library(corrplot)
library(igraph)
library(psych)   

#increase to max memory limit if using windows -- hash out for mac 
memory.limit(10000000000000) 

```

```{r, warning = F, echo=F, include=F}

### This script must be saved in the same folder as the bootstrapped cluster output CSVs in order for the data to read in 

# read in data from cluster output into a list
#setwd("C:/Users/jacob.derosa/Desktop/Scripts/Baggin_Subtyping/CBCL/Boot_Data")
setwd("C:/Users/jacob.derosa/Desktop/Scripts/Baggin_Subtyping/CBCL/home/jderosa/Documents/Baggin_Subtyping/Output/data/csv")

```

```{r, warning = F, echo=F, include=F}

my_data = lapply(list.files(pattern = glob2rx("*CBCL_Cluster_1*.csv")), read.csv, header = T, sep = ",") 

python_df = read.csv("C:/Users/jacob.derosa/Desktop/Scripts/Baggin_Subtyping/CBCL/Splits/CBCL_Split_1.csv", header = T, sep = ",") %>% rename(Key = X)
python_list = list(python_df) #put python df into list that will merged with sample split dfs 
df_list = Map(full_join, my_data, python_list, by = c("Key")) #Combine clustered data with data frame that contains CBCL scores and subject ID 

#initialize empty lists
boot = list() #contains data frame of cluster outputs and subject IDS. 
boot_NA = list() #list of subjects that were not included in the bootsrapped data and contain NA's, used to generate a list of subjects that will be removed from the adjacency matrix
list = list() #list of subjects to be removed from the adjacency matrix
adj = list() #list of adjacency matrices 
boot_mask = list() #contains data frame of cluster outputs and subject IDS. 
boot_NA_mask = list() #list of subjects that were not included in the bootsrapped data and contain NA's, used to generate a list of subjects that will be removed from the adjacency matrix
mask_list = list() #list of subjects to be removed from the adjacency matrix
mask = list() ##list of adjacency matrices 

for(i in 1:length(df_list)){
  boot[[i]] = df_list[[i]]
  boot[[i]] = df_list[[i]][!duplicated(df_list[[i]]$Key),]#remove duplicate subject IDs from bootstrapped data. If no duplicate data is present no subjects will be removed (ex: non bootstrapped data set)
  boot[[i]]$cluster = boot[[i]]$cluster %>% replace_na(0)#Give all subjects a 0 as a cluster label of 0 that did not go into the dataset 
  boot_NA[[i]] = boot[[i]] %>% filter(cluster == 0) #create a list of all subject IDs that have a cluster label of 0 (important for when their row and column are removed from the adjacency matrix)
  list[[i]] = boot_NA[[i]]$Key #assign subjects wuth a 0 to this list 
  adj[[i]] <- +(outer(boot[[i]]$cluster, boot[[i]]$cluster, FUN='=='))*!diag(dim(boot[[i]])[1]) #create the adjacency matrix with 1 and 0: 1 for subjects that have the same cluster assignment as another subject and 0 for subjects that do not have the same cluster assignment. 
  diag(adj[[i]]) <- 0 #set the diagonal of the adjacency matrix to 0
  dimnames(adj[[i]]) <- rep(list(boot[[i]]$Key),2) #Add subject ID to the matrix as column and row headers 
  adj[[i]] = adj[[i]][!rownames(adj[[i]]) %in% list[[i]], !colnames(adj[[i]]) %in% list[[i]]] #remove subjects who had a cluster of 0 with form the previously generated list. 
  ## Create Masks 
  boot_mask[[i]] = df_list[[i]]
  boot_mask[[i]] = df_list[[i]][!duplicated(df_list[[i]]$Key),]#remove duplicate subject IDs from bootstrapped data. If no duplicate data is present no subjects will be removed (ex: non bootstrapped data set)
  boot_mask[[i]]$cluster = boot_mask[[i]]$cluster %>% replace_na(0)
  boot_mask[[i]] = boot_mask[[i]] %>% mutate(cluster = ifelse(cluster == 0, 0, 1)) #create mask matrix, 1 if included in the boostrapped iteration, 0 if not included. 
  #Give all subjects a 0 as a cluster label of 0 that did not go into the dataset 
  boot_NA_mask[[i]] = boot_mask[[i]] %>% filter(cluster == 0) #create a list of all subject IDs that have a cluster label of 0 (important for when their row and column are removed from the adjacency matrix)
  mask_list[[i]] = boot_NA_mask[[i]]$Key #assign subjects wuth a 0 to this list 
  mask[[i]] <- +(outer(boot_mask[[i]]$cluster, boot_mask[[i]]$cluster, FUN='=='))*!diag(dim(boot_mask[[i]])[1]) #create the adjacency matrix with 1 and 0: 1 for subjects that have the same cluster assignment as another subject and 0 for subjects that do not have the same cluster assignment. 
  diag(mask[[i]]) <- 0 #set the diagonal of the adjacency matrix to 0
  dimnames(mask[[i]]) <- rep(list(boot_mask[[i]]$Key),2) #Add subject ID to the matrix as column and row headers 
  mask[[i]] = mask[[i]][!rownames(mask[[i]]) %in% mask_list[[i]], !colnames(mask[[i]]) %in% mask_list[[i]]] 
}


adj_full_1 = acast(rbind(melt(adj[1:100])), Var1~Var2, sum)
mask_full_1 = acast(rbind(melt(mask[1:100])), Var1~Var2, sum)
stab_full_split_1 = adj_full_1/mask_full_1 
diag(stab_full_split_1) = 0
```

```{r, warning = F, echo=F, include=F}

my_data2 = lapply(list.files(pattern = glob2rx("*CBCL_Cluster_2*.csv")), read.csv, header = T, sep = ",")
python_df2 = read.csv("C:/Users/jacob.derosa/Desktop/Scripts/Baggin_Subtyping/CBCL/Splits/CBCL_Split_2.csv", header = T, sep = ",") %>% rename(Key = X) 
python_list2 = list(python_df) 

df_list2 = Map(full_join, my_data2, python_list2, by = c("Key"))

boot_2 = list() #contains data frame of cluster outputs and subject IDS. 
boot_2_NA = list() #list of subjects that were not included in the boot_2strapped data and contain NA's, used to generate a list of subjects that will be 
list2 = list() #list of subjects to be removed from the adjacency matrix
boot_mask2 = list() #contains data frame of cluster outputs and subject IDS. 
boot_NA_mask2 = list() #list of subjects that were not included in the bootsrapped data and contain NA's, used to generate a list of subjects that will be removed from the adjacency matrix
mask_list2 = list() #list of subjects to be removed from the adjacency matrix
mask2 = list() #list of mask adjacency matrices 

adj_2 = list() #list of adjacency matrices 
for(i in 1:length(df_list2)){
  boot_2[[i]] = df_list2[[i]]
  boot_2[[i]] = df_list2[[i]][!duplicated(df_list2[[i]]$Key),]#remove duplicate subject IDs from boot_2strapped data. If no duplicate data is present no subjects will be removed (ex: non boot_2strapped data set)
  boot_2[[i]]$cluster = boot_2[[i]]$cluster %>% replace_na(0)#Give all subjects a 0 as a cluster label of 0 that did not go into the dataset 
  boot_2_NA[[i]] = boot_2[[i]] %>% filter(cluster == 0) #create a list of all subject IDs that have a cluster label of 0 (important for when their row and column are removed from the adj_2acency matrix)
  list2[[i]] = boot_2_NA[[i]]$Key #assign subjects wuth a 0 to this list 
  adj_2[[i]] <- +(outer(boot_2[[i]]$cluster, boot_2[[i]]$cluster, FUN='=='))*!diag(dim(boot_2[[i]])[1]) #create the adjacency matrix with 1 and 0: 1 for subjects that have the same cluster assignment as another subject and 0 for subjects that do not have the same cluster assignment. 
  diag(adj_2[[i]]) <- 0 #set the diagonal of the adj matrix to 0
  dimnames(adj_2[[i]]) <- rep(list(boot_2[[i]]$Key),2) #Add subject ID to the matrix as column and row headers 
  adj_2[[i]] = adj_2[[i]][!rownames(adj_2[[i]]) %in% list2[[i]], !colnames(adj_2[[i]]) %in% list2[[i]]] #remove subjects who had a cluster of 0 with form the previously generated list. 
  
  boot_mask2[[i]] = df_list2[[i]]
  boot_mask2[[i]] = df_list2[[i]][!duplicated(df_list2[[i]]$Key),]#remove duplicate subject IDs from bootstrapped data. If no duplicate data is present no subjects will be removed (ex: non bootstrapped data set)
  boot_mask2[[i]]$cluster = boot_mask2[[i]]$cluster %>% replace_na(0)
  boot_mask2[[i]] = boot_mask2[[i]] %>% mutate(cluster = ifelse(cluster == 0, 0, 1))
  #Give all subjects a 0 as a cluster label of 0 that did not go into the dataset 
  boot_NA_mask2[[i]] = boot_mask2[[i]] %>% filter(cluster == 0) #create a list of all subject IDs that have a cluster label of 0 (important for when their row and column are removed from the adjacency matrix)
  mask_list2[[i]] = boot_NA_mask2[[i]]$Key #assign subjects wuth a 0 to this list 
  mask2[[i]] <- +(outer(boot_mask2[[i]]$cluster, boot_mask2[[i]]$cluster, FUN='=='))*!diag(dim(boot_mask2[[i]])[1]) #create the adjacency matrix with 1 and 0: 1 for subjects that have the same cluster assignment as another subject and 0 for subjects that do not have the same cluster assignment. 
  diag(mask2[[i]]) <- 0 #set the diagonal of the adjacency matrix to 0
  dimnames(mask2[[i]]) <- rep(list(boot_mask2[[i]]$Key),2) #Add subject ID to the matrix as column and row headers 
  mask2[[i]] = mask2[[i]][!rownames(mask2[[i]]) %in% mask_list2[[i]], !colnames(mask2[[i]]) %in% mask_list2[[i]]] 

}

adj_full_2 = acast(rbind(melt(adj_2[1:100])), Var1~Var2, sum)
mask_full_2 = acast(rbind(melt(mask2[1:100])), Var1~Var2, sum)
stab_full_split_2 = adj_full_2/mask_full_2
diag(stab_full_split_2) = 0
```

```{r, include=F, echo = F}

#obtain Key (subject identifier) from the stability matrices and place them into a new data frame 
subs = data.frame("Key" = as.factor(colnames(stab_full_split_1)))# Split 1 

subs2 = data.frame("Key" = as.factor(colnames(stab_full_split_2))) # Split 2


```

# Louvain Final Clustering Solutions
```{r, echo =F, include=F}

G1 <- graph.adjacency(stab_full_split_1, mode = "undirected", weighted = TRUE, diag = TRUE) #turn final stability matrix into a graph, Weighted NEEDS = TRUE, if not there will be over 100 cluster assignments!!!
clusterlouvain <- cluster_louvain(G1) 
subs$cluster = factor(clusterlouvain$membership) 

python_df$Key = factor(python_df$Key)
Split_1 = subs %>% inner_join(python_df, by = c("Key")) %>% mutate(cluster = ifelse(cluster == 1, 3,
                                                                                   ifelse(cluster == 2, 1,
                                                                                          ifelse(cluster == 3,2,
                                                                                                 ifelse(cluster == 4, 4,NA)))))#add cluster assignments to dataset 


G2 <- graph.adjacency(stab_full_split_2, mode = "undirected", weighted = TRUE, diag = TRUE)
clusterlouvain2 <- cluster_louvain(G2)
subs2$cluster = factor(clusterlouvain2$membership)

python_df2$Key = factor(python_df2$Key)
Split_2 = subs2 %>% inner_join(python_df2, by = c("Key")) #add cluster assignments to dataset 


```

# ***Heatmaps***

```{r, echo = F}

gr.row <- subs$cluster # cluster assignments
col1 <- brewer.pal(6, "Set1")

heatmap.2(stab_full_split_1,
          #Rowv=as.dendrogram(hyb1),
          #Colv=as.dendrogram(hyb1),
          RowSideColors=col1[gr.row],
          col=viridis_pal(),
          labRow = F,
          labCol = F,
          main = "Split 1 Heatmap",
          trace = "none")


gr.row <- subs2$cluster # cluster assignments
col1 <- brewer.pal(6, "Set1")

heatmap.2(stab_full_split_2,
          #Rowv=as.dendrogram(hyb1),
          #Colv=as.dendrogram(hyb1),
          RowSideColors=col1[gr.row],
          col=viridis_pal(),
          labRow = F,
          labCol = F,
          main = "Split 2 Heatmap",
          trace = "none")
```


```{r, echo = F, include = F}

#From data sets for each split with clusters and CBCL scores begin by grouping CBCL scores by cluster then create mean for each CBCL subscale summarised by cluster
list = list(`Split 1` = Split_1, `Split 2` = Split_2)
split = list()


for (i in 1:length(list)){
  split[[i]] = list[[i]] %>%
     select(cluster, CBCL_AD_T,  CBCL_WD_T, CBCL_SC_T, CBCL_SP_T, CBCL_TP_T, CBCL_RBB_T, CBCL_AP_T, CBCL_AB_T) %>%
  rename("Anxious Depressed" = CBCL_AD_T) %>%
  rename("Rule Breaking" = CBCL_RBB_T) %>%
  rename("Withdrawn Depressed" = CBCL_WD_T) %>%
  rename("Thought Problems" = CBCL_TP_T) %>%
  rename( "Sommatic Complaints" = CBCL_SC_T) %>%
  rename("Attention Problems" = CBCL_AP_T) %>%
  rename("Agressive Behavior" = CBCL_AB_T) %>%
  rename("Social Problems" = CBCL_SP_T) %>%
    group_by(cluster) %>%
    summarise(
    `Anxious Depressed` = mean(`Anxious Depressed`),
    `Rule Breaking` = mean(`Rule Breaking`),
    `Withdrawn Depressed` = mean(`Withdrawn Depressed`) ,
    `Thought Problems` = mean(`Thought Problems`) ,
    `Sommatic Complaints` = mean(`Sommatic Complaints`) ,
    `Attention Problems` = mean(`Attention Problems`) ,
    `Agressive Behavior` = mean(`Agressive Behavior`) ,
    `Social Problems` = mean(`Social Problems`))
  names(split)[i] = names(list)[[i]]
}

#create 2 seperate lists for split 1 and split 2 that contain each split's cluster's mean cbcl subscale scores by iterations 
# both lists will be later joined together in a list 
Splits = list(`Split 1`= split["Split 1"], `Split 2`= split["Split 2"]) 
full_splits = do.call(Map, c(f = rbind, Splits)) #row binds both split lists together by matching interation. Creates cluster x subscale matrix with mean 
transposeList<- t(full_splits[1])
split_mat = data.frame(transposeList[1]) %>% select(-cluster)
cor_split = cor(t(split_mat), method = "pearson", use="pairwise.complete.obs") #function to apply pearson correlation on each subscale x cluster matrix 
cor = list(cor_split)

# create empty lists to store matched clusters max correlation values 
results = list() #empty list that goes through 2 steps: 1) intialized to have 3 columns (Var 1 = cluster from split 1, Var 2 = cluster from split 2, Cor = max correlation value between the matched clusters)
maxval = list() #empy list that will be used to store the maxium correlation value at each step of the max correlation process 
max = list() #empty list that will be used to store highest matched cluster max correlation values after each iteration and turn their scores to 0 back in the correlation matrix once matched to the loop will match the next clusters by max correlation. 
# loop through each correlation matrix and look at the maximum correlation at each step. So the first step will not look only at the first row, but at the whole matrix
for (i in 1:length(cor)){
  rownames(cor[[i]]) <- colnames(cor[[i]]) #cluster rows are renamed to letter assingments that will be matched under Var 1 and Var2.
  results[[i]] <- data.frame(v1=character(0), v2=character(0), cor=numeric(0), stringsAsFactors=FALSE)
  diag(cor[[i]]) <- 0 #set diagonal to 0 prevent self correlation matching 
  
  #loops through each correlation maxtrix and match clusters  
  while (sum(cor[[i]]>0)>1) {
    maxval[[i]] <- max(cor[[i]]) 
    max[[i]] <- which(cor[[i]]==maxval[[i]], arr.ind=TRUE)[1,]
    results[[i]] <- rbind(results[[i]], data.frame(v1=rownames(cor[[i]])[max[[i]][1]], v2=colnames(cor[[i]])[max[[i]][2]], cor=maxval[[i]]))
    cor[[i]][max[[i]][1],] <- 0
    cor[[i]][,max[[i]][1]] <- 0
    cor[[i]][max[[i]][2],] <- 0
    cor[[i]][,max[[i]][2]] <- 0
  }
  matchedcors <- lapply(results,function(x){t(x[,3])}) #extracts only matched cluster's correlation value by for each results list that are in long form and transposes it to wide format  
}


cor = list(cor_split = cor_split)
cormat = list()
upper_tri = list()
dd = list()
hh = list()
melted_cormat = list()
lower_tri = list()
#Compute the max correlation matrix heatmap of  matched clusters max correlation values 
for(i in 1:length(cor)){
  cormat[[i]] = round(cor[[i]], 2) #round correlation matrix values to include only 2 numbers 
  round(cor(cormat[[i]], use="pairwise.complete.obs"), 2)
  # Get lower triangle of the correlation matrix
  get_lower_tri<-function(cormat){
  cormat[upper.tri(cormat)] <- NA
  return(cormat)
  }
# Get upper triangle of the correlation matri
  get_upper_tri <- function(cormat){
  cormat[lower.tri(cormat)]<- NA
  return(cormat)
  }
  upper_tri[[i]] <- get_upper_tri(cormat[[i]])
  lower_tri[[i]] <- get_lower_tri(cormat[[i]])
  reorder_cormat <- function(cormat){
 # Use correlation between variables as distance
  dd <- as.dist((1-cormat)/2)
  hc <- hclust(dd)
  cormat <-cormat[hc$order, hc$order]
  }
  cormat[[i]] <- reorder_cormat(cormat[[i]])
  upper_tri[[i]] <- get_upper_tri(cormat[[i]])
  melted_cormat[[i]] <- melt(upper_tri[[i]], na.rm = TRUE)
  results[[i]]$cor = round(results[[i]]$cor, 2)
}
reuslts_split = data.frame(results[1])

```

## ***Cluster Profiles*** 

# Split 1
```{r, echo = F, fig.height= 10, fig.width=15}

data <- plyr::ldply(split[1], data.frame)[-1]

colors_line = c(scales::alpha("#440154FF", 1),
                scales::alpha("#3B528BFF", 1),
                scales::alpha("#73D055FF", 1),
                scales::alpha("#FDE725FF", 1))

data = gather(data, "Var", "Mean", `Anxious.Depressed`:`Social.Problems`, factor_key = F) %>% rename(Subtype = cluster)
data$Subtype = factor(data$Subtype)
#Turn your 'treatment' column into a character vector
data$Var <- as.character(data$Var)
#Then turn it back into a factor with the levels in the correct order
data$Var <- factor(data$Var, levels=unique(data$Var))

ggplot(data, aes(x=factor(Var), y=Mean, group=Subtype)) +
  geom_line(aes(color = Subtype), size = 5) +
   labs(x="", y="") +
  ggtitle("") +
  #scale_colour_manual(values=colors_line) +
  scale_colour_manual(values=col1) +
  theme(axis.line = element_line(size=2, colour = "black"),
        panel.grid.major = element_line(colour = "#d3d3d3"), panel.grid.minor = element_blank(),
        panel.border = element_blank(), panel.background = element_blank()) +
  theme(plot.title = element_text(size = 14, face = "bold"),
        axis.text.x=element_text(colour="black", size = 10),
        axis.text.y=element_text(colour="black", size = 10),
        legend.key=element_rect(fill="white", colour="white")) + 
    theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust=1, size= 23, face = "bold")) +
  theme(
    panel.grid.major = element_line(colour = "black", linetype = "dotted", size = 1.5),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(), 
          axis.text.y = element_text(face="bold", color="black", 
                           size=20),
    axis.ticks.length=unit(0.3,"cm"),
    axis.ticks.x=element_line(size=2),
    axis.ticks.y=element_line(size=2)) + 
  theme(
    legend.title = element_text(size = 30), 
    legend.text = element_text(size = 30)) + 
  scale_y_continuous(limits = c(50, 70)) 

```

# Split 2
```{r, echo = F, fig.height= 10, fig.width=15}

data_2 <- plyr::ldply(split[2], data.frame)[-1] 

data_2 = gather(data_2, "Var", "Mean", `Anxious.Depressed`:`Social.Problems`, factor_key = F) %>%
  rename(Subtype = cluster)
data_2$Subtype = factor(data_2$Subtype)
#Turn your 'treatment' column into a character vector
data_2$Var <- as.character(data_2$Var)
#Then turn it back into a factor with the levels in the correct order
data_2$Var <- factor(data_2$Var, levels=unique(data_2$Var))

ggplot(data_2, aes(x=factor(Var), y=Mean, group=Subtype)) +
  geom_line(aes(color = Subtype), size = 5) +
   labs(x="", y="") +
  ggtitle("") +
  #scale_colour_manual(values=colors_line) +
  scale_colour_manual(values=col1) +
  theme(axis.line = element_line(size=2, colour = "black"),
        panel.grid.major = element_line(colour = "#d3d3d3"), panel.grid.minor = element_blank(),
        panel.border = element_blank(), panel.background = element_blank()) +
  theme(plot.title = element_text(size = 14, face = "bold"),
        axis.text.x=element_text(colour="black", size = 10),
        axis.text.y=element_text(colour="black", size = 10),
        legend.key=element_rect(fill="white", colour="white")) + 
    theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust=1, size= 23, face = "bold")) +
  theme(
    panel.grid.major = element_line(colour = "black", linetype = "dotted", size = 1.5),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(), 
          axis.text.y = element_text(face="bold", color="black", 
                           size=20),
    axis.ticks.length=unit(0.3,"cm"),
    axis.ticks.x=element_line(size=2),
    axis.ticks.y=element_line(size=2)) + 
  theme(
    legend.title = element_text(size = 30), 
    legend.text = element_text(size = 30)) + 
  scale_y_continuous(limits = c(50, 70))       

```

```{r, echo = F, include = F}

ggheatmap <- ggplot(reuslts_split, aes(v2, v1, fill = cor))+
  geom_tile(color = "white")+
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Pearson Correlation") +
  theme_minimal()+ # minimal theme
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1))+
  theme(axis.text.y = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1))+
  coord_fixed()

```

## ***Mean Matched Max Correlations*** 
```{r, echo = F, fig.width=7, fig.height=10}

ggheatmap + 
  geom_text(aes(v2, v1, label = cor), color = "black", size = 4) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.ticks = element_blank(),
    legend.justification = c(1, 0),
    legend.position = c(0.4, 0.7),
    legend.direction = "horizontal")+
  guides(fill = guide_colorbar(barwidth =5, barheight = 1,
                               title.position = "top", title.hjust = 0.3)) + 
  labs(title="                                                ") + 
  theme(plot.title = element_text(size=14, face="bold.italic")) 
  
  
```

```{r, warning = F,echo = F, include = F}

col<- colorRampPalette(c("blue","red"))(100)

cor_lowers = data.frame(cormat[1])
cor_lowers = as.matrix(cor_lowers)

```

## ***Correlations***
```{r, warning = F,echo = F, fig.width=7, fig.height=10}


corrplot(cor_lowers, method="color", col=col,  
         type="lower", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # hide correlation coefficient on the principal diagonal
         diag=FALSE, 
        mar=c(0,0,1,0))

```