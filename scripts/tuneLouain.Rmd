---
title: "tuneLouain"
author: "Ian Douglas"
date: "6/18/2020"
output: html_document
---
```{r}
library(igraph)
library(phenoGraph)
library(KernelKnn)
library(parallel)
library(doParallel)
library(tidyverse)
library(mclust)
```

# Define the helper function
The function `hybrid_cluster` will wrap the the two-step louvain clustering procedure: 1.graph construction; 2. community detection. This will enable us to "tune" hyperparameters of the algorithm
```{r}
hybrid_clust = function(data, num.neighbors = "default", Hadamard = TRUE, distance = "euclidean")
{
  # Hybrid_clust allows you to conduct the entire phenoGraph::phenoClust()
  # algorithm (both steps) using a combination of igraph and 
  # phenoGraph (hence the name "hybrid") functions. iGraph is implemented in 
  # C++ (via Rcpp), so the slow louvain() function is supplanted by 
  # igraph::cluster_louvain (10x times faster), but `hybrid_clust` also 
  # makes use of phenoGraph::hadamard to conveniently filter the data prior 
  # to running louvain algorithm. Also, the default number of neighbors is
  # N / ceiling(log2(N) + 1), [equivalent to N / nclass.Sturges(N)], whereas
  # the default in phenoGraph is simply nclass.Sturges(N), or ceiling(log2(N) + 1)
  
  if (num.neighbors == "default") {
    num.neighbors <- ceiling(nrow(data)/ceiling(log2(nrow(data) + 1)))
  } else num.neighbors <- as.numeric(num.neighbors)
  .hadamard <- as.logical(Hadamard)
  .dist <- as.character(distance)
  
  param_grid = expand.grid()
  # (1) Obtain an adjacency matrix, defining an edge between each subject and their nearest neighbor
  # Place this value in a weighted adjacency matrix
  adj <- matrix(0, nrow = nrow(data), ncol = nrow(data))
  knn <- knn.index.dist(data, k = num.neighbors, method = .dist) # defaults to euclidean distance
  for (i in 1:nrow(data)) {
    for (j in 1:num.neighbors) {
      neighbor <- knn$train_knn_idx[i, j]
      adj[i, neighbor] <- adj[neighbor, i] <- 1
    }
  }
  
  if (.hadamard) {
    adj <- phenoGraph::hadamard(adj)
  }
  
  G <- igraph::graph_from_adjacency_matrix(adjmatrix = adj,
                                           mode = "undirected",
                                           weighted = TRUE,
                                           diag = F)
  # (3) Conduct louvain community detection
  cl <- igraph::cluster_louvain(G)
  
  return(
    list(
      "cluster_labels" = cl$membership,
      "optimal.k" = n_distinct(cl$membership),
      "modularity" = max(cl$modularity) # extract the modularity from the optimal iteration
    )
  )
}
```

# Read in the HBN CBCL data
```{r}
Basic_Demos <- read.csv("../../data/HBN/Basic_Demos_r8.csv", header =T, sep = ",")  %>%
  select(URSI, Age, Sex) %>%
  rename(Ages = Age)

Diagnosis <- read.csv("../../data/HBN/Diagnosis.csv", header = T, sep = ",") %>%
  rename(ANX = `Anxiety.Disorders`) %>%
  rename(ASD = `Autism.Spectrum.Disorder`) %>%
  rename(ADHD = `Attention.Deficit.Hyperactivity.Disorder`) %>%
  rename(DEP = `Depressive.Disorders`) %>%
  rename(NT = `No.Diagnosis.Given`) %>%
  rename(LD = Learning_Disorder) %>%
  rename(ADHD_C = ADHD.Combined.Type) %>%
  rename(ADHD_I = ADHD.Inattentive.Type) %>%
  rename(ADHD_H = ADHD.Hyperactive.Impulsive.Type) %>%
  rename(ODD = Oppositional.Defiant.Disorder) %>% 
  select(-X, -starts_with("Specific"))

CBCL <- read.csv("../../data/HBN/CBCL_r8.csv", header =T, sep = ",") %>% select(URSI, ends_with("_T"))

CBCL = CBCL %>% inner_join(Diagnosis, by = "URSI") %>% inner_join(Basic_Demos, by = "URSI") %>% mutate(Ages = floor(Ages))
# Parse out X variables from the labels
CBCL.X <- CBCL[!names(CBCL) %in% names(Basic_Demos)] # also drops URSI
CBCL.labels <- CBCL %>% select(all_of(names(Basic_Demos)))
```

# Tune the louvain clustering for different values of k, and whether to binarize or not
```{r}
# set up the param grid:
param_grid = expand.grid("nn" = unique(round(sort(c(seq(1, 150, length.out = 10),
                                                    nclass.Sturges(1:nrow(CBCL.X)), 
                                                    ceiling(nrow(CBCL.X) / nclass.Sturges(1:nrow(CBCL.X))))))),
                         "had" = c(TRUE, FALSE),
                         "dist" = c("euclidean", "pearson_correlation", "mahalanobis"),
                         stringsAsFactors = F)
# activate a 3-core cluster
cl <- makeCluster(getOption("cl.cores", 3))
# load objects (the data, param grid, the custom function) into the cluster of cores
clusterExport(cl, list("hybrid_clust", "param_grid", "CBCL.X"))
# load packages into the cluster
clusterEvalQ(cl, library(phenoGraph))
clusterEvalQ(cl, library(KernelKnn))
clusterEvalQ(cl, library(tidyverse))
clusterEvalQ(cl, library(igraph))
# Run hybrid_louvain on each combination of tuning parameters
t0 <- Sys.time()
louv_tune = parApply(cl = cl, X = param_grid, MARGIN = 1, FUN = function(x) {
  hybrid_clust(CBCL.X, 
               num.neighbors = x[1], 
               Hadamard = x[2], 
               distance = x[3])
})
elapsed = Sys.time() - t0
saveRDS(louv_tune, "../output/louvainTuning.rds")
stopCluster(cl) # shut down cluster
beepr::beep()
elapsed
```

# Heatmap of adjusted Rand Indices pertaining to the results
```{r}
param_grid %>%
  rowwise() %>%
  mutate(iter = paste0(nn,".",had,".",dist)) %>%
  select(iter) -> results
clusterLabels = purrr::map(louv_tune, ~.$cluster_labels)
#names(clusterLabels) <- results$iter
allIndices = combn(seq_along(clusterLabels), 2)
allRands = NULL
method1=NULL
method2=NULL
for (i in 1:ncol(allIndices)) {
  method1[i] <- results$iter[allIndices[1, i]]
  method2[i] <- results$iter[allIndices[2, i]]
  allRands[i] <- adjustedRandIndex(clusterLabels[[allIndices[1, i]]], clusterLabels[[allIndices[2, i]]])
}

# Generate rand index between all pairwise clusterings
plt.dat = data.frame(method1 = method1,
                     method2 = method2,
                     rand = allRands,
                     stringsAsFactors = F)
# Wrap this up to the dimensions of a heatmap
heat.mat <- matrix(0, nrow = nrow(param_grid), ncol = nrow(param_grid))
indexer <- 1
LWR.TRI <- lower.tri(heat.mat, diag = F)
for (col in 1:ncol(LWR.TRI)) {
  for (row in 1:nrow(LWR.TRI)) {
    if (LWR.TRI[row, col]) {
      heat.mat[row, col] <-allRands[indexer]
      indexer <- indexer + 1
    }
  }
}
diag(heat.mat) <- 1
rownames(heat.mat) <- colnames(heat.mat) <- do.call(paste0, lapply(param_grid,function(x) x))
# Reorder it:
reorder_RandMat <- function(mat){
dd <- as.dist((1-mat)/2)
hc <- hclust(dd)
mat <-mat[hc$order, hc$order]
mat
}
# Reordered
reorder_heatmat = reorder_RandMat(heat.mat)
# Get upper triangle inds
get_lower_tri <- function(heatmat) {
  heatmat[upper.tri(heatmat)]<- NA
  return(heatmat)
}
lower_tri <- get_lower_tri(reorder_heatmat)
# Melt the correlation matrix
melted_heatmat <- reshape2::melt(upper_tri, na.rm = TRUE)
```
```{r}
# Create a ggheatmap
ggheatmap <- ggplot(melted_heatmat, aes(Var2, Var1, fill = value)) +
 geom_tile(color = "white") +
 scale_fill_gradient2(low = "red", high = "blue", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
    name="Adjusted Rand\nIndex") +
  theme_minimal()+ # minimal theme
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                  size = 10, hjust = 1))+
 coord_fixed() + 
  ggtitle("Similarity Between Louvain Clustering Solutions using Different Hyperparameter Settings") + 
  labs(caption = "Note. Variable names start with the number of neighbors used to \ngenerate the adjacency matrix. TRUE/FALSE indicate if that adjacency matrix was converted to\n a Hadamard matrix (TRUE; resulting in weighted edges) or used as is (resulting in \nunweighted edges). The final element names the distance metric used to create the initial \ndistance matrix passed on to nearest-neighbor binarization.")
# Print the heatmap
print(ggheatmap)
ggsave(plot = ggheatmap,
       filename = "../output/tuneLouvainHeatmap.jpg",
       device = "jpg",
       width = 12, height = 12)
```

The biggest determinant of the composition of the cluster solution is:
(1) The distance metric used as an initial input for creating the adjacency matrix
(2) That the number of neighbors used to transform the distance matrix to an adjacency matrix uses greater thatn 1 nearest-neighbor.